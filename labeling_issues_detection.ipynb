{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9b0342b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from cleanlab import Datalab\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d89c89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90994e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef95fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fasttext\n",
    "\n",
    "# encoder = fasttext.load_model(\"./models/cc.ar.300.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79c5ab2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\ehhho/.cache\\torch\\sentence_transformers\\UBC-NLP_MARBERT. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = f\"cuda:{torch.cuda.current_device()}\" if torch.cuda.is_available() else \"cpu\"\n",
    "encoder = SentenceTransformer(\"UBC-NLP/MARBERT\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78c301fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "clean_data_path = \"./data/irony_clean_data\"\n",
    "processed_data_path = \"./data/irony_processed_data\"\n",
    "train_data_path = \"./data/irony_training_data.csv\"\n",
    "test_data_path = \"./data/irony_testing_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8763d422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"د. #محمود_العلايلي:أرى أن الفريق #أحمد_شفيق ر...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"مع فيدرر يا آجا والكبار 😍 https://t.co/hrBeHb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“الداعون لمبدأ الاختلاط بين الجنسين؛ كالداعين ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"@ihe_94 @ya78m @amooo5 @badiajnikhar @Oukasaf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"قل شرق حلب ولا تقل حلب الشرقية ....وقل غرب حل...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sarcasm\n",
       "0  \"د. #محمود_العلايلي:أرى أن الفريق #أحمد_شفيق ر...        0\n",
       "1  \"مع فيدرر يا آجا والكبار 😍 https://t.co/hrBeHb...        0\n",
       "2  “الداعون لمبدأ الاختلاط بين الجنسين؛ كالداعين ...        1\n",
       "3  \"@ihe_94 @ya78m @amooo5 @badiajnikhar @Oukasaf...        1\n",
       "4  \"قل شرق حلب ولا تقل حلب الشرقية ....وقل غرب حل...        0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(train_data_path)[[\"tweet\", \"sarcasm\"]]\n",
    "train_data[\"sarcasm\"] = train_data.sarcasm.astype(int)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e42c6450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcasm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>اخوي حانق يالغلا وشفيك معصب؟ عادي تراهم بشر يف...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>اف مو متعوده عليهم سته https://t.co/8igFPx1i26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>اللهم اشفِ مرضانا ومرضى المسلمين . . ♥️</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ابشركم طلقت السات 😘.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>مؤشر خطير: ٩٠٪ من الشخصيات البرلمانية في الكوي...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sarcasm\n",
       "0  اخوي حانق يالغلا وشفيك معصب؟ عادي تراهم بشر يف...        0\n",
       "1     اف مو متعوده عليهم سته https://t.co/8igFPx1i26        1\n",
       "2            اللهم اشفِ مرضانا ومرضى المسلمين . . ♥️        0\n",
       "3                               ابشركم طلقت السات 😘.        0\n",
       "4  مؤشر خطير: ٩٠٪ من الشخصيات البرلمانية في الكوي...        1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(test_data_path)[[\"tweet\", \"sarcasm\"]]\n",
    "test_data[\"sarcasm\"] = test_data.sarcasm.astype(int)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a396fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15548 entries, 0 to 15547\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   tweet    15548 non-null  object\n",
      " 1   sarcasm  15548 non-null  int32 \n",
      "dtypes: int32(1), object(1)\n",
      "memory usage: 182.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f0ddd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = DatasetDict(\n",
    "#     {\n",
    "#         \"train\": Dataset.from_pandas(train_data),\n",
    "#         \"test\": Dataset.from_pandas(test_data),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cda71f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tweet', 'sarcasm'],\n",
       "    num_rows: 15548\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(data)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13bb32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    clean_text = re.sub(r\"http\\S+|t\\.co/\\S+\", \"\", text)\n",
    "    clean_text = re.sub(r\"@\\w+\", \"\", clean_text)\n",
    "    clean_text = re.sub(r\"#\", \"\", clean_text)\n",
    "    clean_text = re.sub(r\"_\", \" \", clean_text)\n",
    "    # tashqeel - from @bakriano\n",
    "    clean_text = re.sub(r\"[\\u0617-\\u061A\\u064B-\\u0652]\", \"\", clean_text)\n",
    "    clean_text = emoji.replace_emoji(clean_text, replace=\"\")\n",
    "    clean_text = re.sub(r\"\\s+\", \" \", clean_text)\n",
    "    return clean_text.replace(\"RT :\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "803c4b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15548 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'text'],\n",
       "    num_rows: 15548\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.rename_column(\"sarcasm\", \"labels\")\n",
    "clean_data = dataset.map(\n",
    "    lambda x: {\"text\": [clean_text(t) for t in x[\"tweet\"]]},\n",
    "    batched=True,\n",
    "    remove_columns=[\"tweet\"],\n",
    ")\n",
    "\n",
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85a8e332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/15548 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_data.save_to_disk(processed_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38c89ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(batch):\n",
    "    # return {\"features\": [encoder.get_sentence_vector(t) for t in batch[\"text\"]]}\n",
    "    return {\n",
    "        \"features\": encoder.encode(batch[\"text\"], convert_to_numpy=True, device=device)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "917bba34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15548 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_data = clean_data.map(vectorize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0389f312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.884174692793092, 1: 0.11582530720690801}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = encoded_data.to_pandas().labels.value_counts(normalize=True).to_list()\n",
    "w = {i: w[i] for i in range(len(w))}\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3ace544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\"penalty\": \"l1\", \"solver\": \"liblinear\", \"C\": 1000.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f4e20028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(\n",
    "    class_weight=w, random_state=seed, max_iter=int(1e5), verbose=1, **train_params\n",
    ")\n",
    "pred_probs = cross_val_predict(\n",
    "    estimator=model,\n",
    "    X=encoded_data[:][\"features\"],\n",
    "    y=encoded_data[:][\"labels\"],\n",
    "    cv=10,\n",
    "    method=\"predict_proba\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "360f7608",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = encoded_data.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fd30ef09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding label issues ...\n",
      "Finding outlier issues ...\n",
      "Fitting OOD estimator based on provided features ...\n",
      "Finding near_duplicate issues ...\n",
      "Audit complete. 579 issues found in the dataset.\n"
     ]
    }
   ],
   "source": [
    "lab = Datalab(data, label_name=\"labels\")\n",
    "lab.find_issues(pred_probs=pred_probs, features=np.array(data[\"features\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c8ebd514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summary of the different kinds of issues found in the data:\n",
      "\n",
      "    issue_type  num_issues\n",
      "near_duplicate         572\n",
      "         label           5\n",
      "       outlier           2\n",
      "\n",
      "Dataset Information: num_examples: 12044, num_classes: 2\n",
      "\n",
      "\n",
      "------------------ near_duplicate issues -------------------\n",
      "\n",
      "About this issue:\n",
      "\tA (near) duplicate issue refers to two or more examples in\n",
      "    a dataset that are extremely similar to each other, relative\n",
      "    to the rest of the dataset.  The examples flagged with this issue\n",
      "    may be exactly duplicated, or lie atypically close together when\n",
      "    represented as vectors (i.e. feature embeddings).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 572\n",
      "Overall dataset quality in terms of this issue: 0.0030\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "      is_near_duplicate_issue  near_duplicate_score                                          near_duplicate_sets  distance_to_nearest_neighbor\n",
      "7117                     True                   0.0  [4568, 3546, 105, 4843, 7422, 8897, 1903, 5267, 5115, 4124]                           0.0\n",
      "1191                     True                   0.0   [8531, 9903, 7733, 3635, 8696, 3302, 713, 6219, 313, 6932]                           0.0\n",
      "4245                     True                   0.0  [604, 4843, 2087, 1646, 9968, 1442, 6632, 4641, 4568, 7117]                           0.0\n",
      "7976                     True                   0.0    [4369, 3495, 440, 2956, 829, 8152, 6932, 318, 5130, 4066]                           0.0\n",
      "4369                     True                   0.0    [7976, 3495, 440, 2956, 829, 8152, 6932, 318, 5130, 4066]                           0.0\n",
      "\n",
      "\n",
      "----------------------- label issues -----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples whose given label is estimated to be potentially incorrect\n",
      "    (e.g. due to annotation error) are flagged as having label issues.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 5\n",
      "Overall dataset quality in terms of this issue: 0.9996\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "       is_label_issue  label_score  given_label  predicted_label\n",
      "11177            True     0.000719            1                0\n",
      "6469            False     0.006437            1                0\n",
      "11806           False     0.007336            1                0\n",
      "10368           False     0.007889            1                0\n",
      "5473            False     0.007919            1                0\n",
      "\n",
      "\n",
      "---------------------- outlier issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples that are very different from the rest of the dataset \n",
      "    (i.e. potentially out-of-distribution or rare/anomalous instances).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 2\n",
      "Overall dataset quality in terms of this issue: 0.9963\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "       is_outlier_issue  outlier_score\n",
      "2759               True       0.993659\n",
      "8484               True       0.993660\n",
      "4250              False       0.993663\n",
      "9869              False       0.993666\n",
      "11134             False       0.993668\n"
     ]
    }
   ],
   "source": [
    "lab.report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "be44857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = lab.get_issues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b417e2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>label_score</th>\n",
       "      <th>is_outlier_issue</th>\n",
       "      <th>outlier_score</th>\n",
       "      <th>is_near_duplicate_issue</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.997248</td>\n",
       "      <td>False</td>\n",
       "      <td>0.002209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.996134</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.995298</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.995170</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>False</td>\n",
       "      <td>0.995505</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_label_issue  label_score  is_outlier_issue  outlier_score  \\\n",
       "0           False     1.000000             False       0.997248   \n",
       "1           False     1.000000             False       0.996134   \n",
       "2           False     1.000000             False       0.995298   \n",
       "3           False     1.000000             False       0.995170   \n",
       "4           False     0.998774             False       0.995505   \n",
       "\n",
       "   is_near_duplicate_issue  near_duplicate_score  \n",
       "0                    False              0.002209  \n",
       "1                    False              0.000612  \n",
       "2                    False              0.004305  \n",
       "3                    False              0.003874  \n",
       "4                    False              0.004138  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fbe085d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_flag = np.any(issues[[\"is_label_issue\", \"is_outlier_issue\"]], axis=1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5a5f548a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/12044 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'text', 'features', 'is_issued'],\n",
       "    num_rows: 12044\n",
       "})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data = encoded_data.add_column(\"is_issued\", issues_flag)\n",
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "146b1375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/12044 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_data = encoded_data.filter(lambda x: not x[\"is_issued\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "903bb68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = encoded_data.remove_columns(\"is_issued\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c5587c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'text', 'features'],\n",
       "    num_rows: 12037\n",
       "})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "21ab0ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = encoded_data.remove_columns(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e8290530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'text'],\n",
       "    num_rows: 12037\n",
       "})"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9e0f7bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/12037 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_data.save_to_disk(clean_data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
